# -*- coding: utf-8 -*-
"""Submission3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p0LvbWTSbQiJcuE1tqgpZJpD5VHxgBAk

*   Nama: Tuti Amalia
*   Email: tutiamalia111@gmail.com
*   Asal: Kabupaten Gowa
*   Dataset yang digunakan: https://www.kaggle.com/abhi8923shriv/cat-dog-dataset
"""

!nvidia-smi

# library
import tensorflow as tf
import numpy as np
import shutil
import random
import matplotlib.image as mpimg
import matplotlib.pyplot as plt

from matplotlib.image import imread
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dropout, Dense
from tensorflow.keras.models import Sequential

"""Download Dataset"""

from google.colab import files
!pip install -q kaggle

uploaded = files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets list

!kaggle datasets download -d abhi8923shriv/cat-dog-dataset

# melakukan ekstraksi pada file zip
import zipfile,os
fileZip = 'cat-dog-dataset.zip'
zipRef = zipfile.ZipFile(fileZip, 'r')
zipRef.extractall('/content')
zipRef.close()

# melihat total gambar pada masing2 folder
base_dir = '/content/Cat_Dog_data/train/'
class_dir = ['cat', 'dog']

for i in class_dir:
    print('Total gambar {} : '.format(i) + str(len(os.listdir(base_dir + i + '/'))))

"""Menampilkan gambar"""

train_cats_dir = '/content/Cat_Dog_data/train/cat'
train_dogs_dir = '/content/Cat_Dog_data/train/dog'
train_cat_names = os.listdir(train_cats_dir)
train_dog_names = os.listdir(train_dogs_dir)
nrows = 4
ncols = 4

pic_index = 0
pic_index += 8
fig = plt.gcf()
fig.set_size_inches(ncols*4, nrows*4)

next_cat_pix = [os.path.join(train_cats_dir, n) 
                for n in train_cat_names[pic_index-8:pic_index] 
               ]

next_dog_pix = [os.path.join(train_dogs_dir, n) 
                for n in train_dog_names[pic_index-8:pic_index]
               ]

for i, img_path in enumerate(next_cat_pix + next_dog_pix):

  sp = plt.subplot(nrows, ncols, i + 1)
  sp.axis('Off')

  img = mpimg.imread(img_path)
  plt.imshow(img)

plt.show()

# membuat nama direktori
train_dir = os.path.join(base_dir,'train')
val_dir = os.path.join(base_dir, 'val')

# membuat direktori train dan validation
os.makedirs(train_dir, exist_ok = True)
os.makedirs(val_dir, exist_ok = True)

from sklearn.model_selection import train_test_split
import shutil
# untuk memisahkan training set dan validation set
for i in class_dir:
  train_file_names, val_file_names =  train_test_split(os.listdir(os.path.join(base_dir, i)), test_size = 0.2)
  train_class_dir = os.path.join(train_dir, i)
  val_class_dir = os.path.join(val_dir, i)

  # Jika folder ini ada, hapus isinya supaya tidak terjadi penumpukan data ketika dieksekusi berkali2
  if os.path.exists(train_class_dir):
    shutil.rmtree(train_class_dir)

  if os.path.exists(val_class_dir):
    shutil.rmtree(val_class_dir)

  # buat folder baru
  os.makedirs(train_class_dir, exist_ok = True)
  os.makedirs(val_class_dir, exist_ok = True)
  
  # copy isinya dari folder lama ke folder baru
  for tfn in train_file_names:
    shutil.copy(os.path.join(base_dir + i, tfn), train_class_dir)

  for vfn in val_file_names:
    shutil.copy(os.path.join(base_dir + i, vfn), val_class_dir)

  #melihat jumlah masing2 kelas untuk train dan validation
  print('Gambar untuk train {} : {}'.format(i,str(len(os.listdir(train_class_dir)))))
  print('Gambar untuk validasi {} : {}'.format(i,str(len(os.listdir(val_class_dir)))))
  print('\n')

# implementasi image data generator untuk augmentasi gambar
trainDatagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=40,
                    width_shift_range=0.2,
                    height_shift_range=0.2,
                    shear_range=0.2,
                    zoom_range=0.2,
                    horizontal_flip=True,
                    fill_mode='nearest')

testDatagen = ImageDataGenerator(rescale=1./255)

# Augmentasi gambar
size = 128
train_generator = trainDatagen.flow_from_directory(
        train_dir,
        target_size = (224, 224),
        batch_size = size,
        class_mode = 'binary')
  
validation_generator = testDatagen.flow_from_directory(
        val_dir,
        target_size = (224, 224),
        batch_size = size,
        shuffle = False,
        class_mode = 'binary')
num_train = train_generator.n
num_val = validation_generator.n
print(num_train)
print(num_val)

"""Membuat dan Melatih Model menggunakan MobileNetV2"""

MobNet = MobileNetV2(include_top=False, input_shape=(224,224,3))
MobNet.trainable = False

model = Sequential()

model.add(MobNet)
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(2, 2))
model.add(Flatten())
model.add(Dense(1, activation="sigmoid"))

model.summary()

# Compile the model
print('Compiling Model.......')
model.compile(tf.keras.optimizers.Adam(learning_rate=0.0001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

callbacks = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=2)

import datetime
start = datetime.datetime.now()

history = model.fit(train_generator,
        steps_per_epoch=num_train // size,
        epochs=20,
        validation_data=validation_generator,
        validation_steps= num_val // size, 
        callbacks = [callbacks],
        verbose=1)

end= datetime.datetime.now()
elapsed= end-start
print ('Time: ', elapsed)

"""Plotting Akurasi dan Loss"""

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.ylabel('value')
plt.xlabel('No. epoch')
plt.legend(loc="upper left")
plt.show()

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.ylabel('value')
plt.xlabel('No. epoch')
plt.legend(loc="upper left")
plt.show()

"""Simpan TF-Lite"""

# Konversi model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('cat_dog_image_classification.tflite', 'wb') as f:
  f.write(tflite_model)

"""Simpan model"""

model.save('cats_and_dogs.h5')

